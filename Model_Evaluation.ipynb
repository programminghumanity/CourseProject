{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model_Evaluation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNMxr09gHTEG4gqgGMwkSi2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zen030/CourseProject/blob/main/Model_Evaluation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dkl0xauiifVr"
      },
      "source": [
        "# **This notebook is implemented and tested in Google Colab PRO environment**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDPdGFOi54MM"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Lw3uHrhN88Z"
      },
      "source": [
        "!pip install transformers\n",
        "!pip install PyDrive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9R-GnI0pNJQg"
      },
      "source": [
        "# Import the required modules.\n",
        "\n",
        "# Evaluation.\n",
        "import pandas as pd\n",
        "import json\n",
        "from transformers import BertTokenizer\n",
        "from torch.utils.data import TensorDataset\n",
        "from torch.utils.data import DataLoader, SequentialSampler\n",
        "import torch.nn.functional as F \n",
        "import torch\n",
        "from transformers import BertForSequenceClassification\n",
        "import numpy as np\n",
        "\n",
        "# To manage dataset.\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fiyMrtpxfkpl"
      },
      "source": [
        "# model file location: https://drive.google.com/file/d/1sn3QT-GlFvgk7XHv-144WC6gf9gHCAnE/view?usp=sharing\n",
        "# test.jsonl file location: https://drive.google.com/file/d/1vA3uyqy1TZmahgZ0PeNRFx67LuYeAkoW/view?usp=sharing\n",
        "\n",
        "# The pre-trained model using training dataset.\n",
        "# Google Drive file name.\n",
        "model_file = 'lr_2e-5_1e-8_17_4.model'\n",
        "# Google Drive unique file ID\n",
        "model_file_id = \"1sn3QT-GlFvgk7XHv-144WC6gf9gHCAnE\"\n",
        "\n",
        "# The evaluation/testing dataset.\n",
        "# Google Drive file name.\n",
        "evaluation_file = 'test.jsonl'\n",
        "# Google Drive unique file ID.\n",
        "test_jsonl_file_id = \"1vA3uyqy1TZmahgZ0PeNRFx67LuYeAkoW\""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YoFyovRTfn-B"
      },
      "source": [
        "# The files are shared to public.\n",
        "# Login using Google Account to proceed.\n",
        "# Copy-past the code.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "downloaded = drive.CreateFile({'id':test_jsonl_file_id})\n",
        "downloaded.GetContentFile(evaluation_file) \n",
        "\n",
        "downloaded = drive.CreateFile({'id':model_file_id})\n",
        "downloaded.GetContentFile(model_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hO6nF2RTZ_ld",
        "outputId": "4efa1a69-0ad3-4522-da64-d0ca4ba2bbeb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        }
      },
      "source": [
        "# Read jsonl file into list (of json)\n",
        "evaluation_data_file = evaluation_file\n",
        "with open(evaluation_data_file) as f:\n",
        "    # creating array of json\n",
        "    lines = f.read().splitlines()\n",
        "print(f'Number of lines in file: {len(lines)}')\n",
        "\n",
        "# Normalize json into dataframe columns\n",
        "df = pd.json_normalize(pd.DataFrame(lines)[0].apply(json.loads))\n",
        "print(f'Number of records in Pandas DataFrame: {len(df)}')\n",
        "\n",
        "# Lowercase response text\n",
        "# BERT Model can lowercase the text in the setting\n",
        "# I choose to lowercase the text here to have a uniform text format\n",
        "# In case I need to modfiy the text for a reason\n",
        "df.response = df.response.str.lower()\n",
        "\n",
        "# Print DataFrame to have preview of the data\n",
        "df"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of lines in file: 1800\n",
            "Number of records in Pandas DataFrame: 1800\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>response</th>\n",
              "      <th>context</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>twitter_1</td>\n",
              "      <td>@user @user @user my 3 year old , that just fi...</td>\n",
              "      <td>[Well now that ’ s problematic AF &lt;URL&gt;, @USER...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>twitter_2</td>\n",
              "      <td>@user @user how many verifiable lies has he to...</td>\n",
              "      <td>[Last week the Fake News said that a section o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>twitter_3</td>\n",
              "      <td>@user @user @user maybe docs just a scrub of a...</td>\n",
              "      <td>[@USER Let ’ s Aplaud Brett When he deserves i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>twitter_4</td>\n",
              "      <td>@user @user is just a cover up for the real ha...</td>\n",
              "      <td>[Women generally hate this president . What's ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>twitter_5</td>\n",
              "      <td>@user @user @user the irony being that he even...</td>\n",
              "      <td>[Dear media Remoaners , you excitedly sharing ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1795</th>\n",
              "      <td>twitter_1796</td>\n",
              "      <td>@user @user @user is definitely the best out t...</td>\n",
              "      <td>[I have been a business customer of MWeb @USER...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1796</th>\n",
              "      <td>twitter_1797</td>\n",
              "      <td>@user @user ye let her out run wild and infect...</td>\n",
              "      <td>[A woman refuses to have her temperature taken...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1797</th>\n",
              "      <td>twitter_1798</td>\n",
              "      <td>@user @user @user thanks for that , i would ha...</td>\n",
              "      <td>[The reason big government wants @USER out is ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1798</th>\n",
              "      <td>twitter_1799</td>\n",
              "      <td>@user @user @user yes also #found this on #new...</td>\n",
              "      <td>[Happy #musicmonday and #thanks for #all your ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1799</th>\n",
              "      <td>twitter_1800</td>\n",
              "      <td>@user @user @user you still need to send the l...</td>\n",
              "      <td>[Not long wrapped on the amazing #January22nd ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1800 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                id  ...                                            context\n",
              "0        twitter_1  ...  [Well now that ’ s problematic AF <URL>, @USER...\n",
              "1        twitter_2  ...  [Last week the Fake News said that a section o...\n",
              "2        twitter_3  ...  [@USER Let ’ s Aplaud Brett When he deserves i...\n",
              "3        twitter_4  ...  [Women generally hate this president . What's ...\n",
              "4        twitter_5  ...  [Dear media Remoaners , you excitedly sharing ...\n",
              "...            ...  ...                                                ...\n",
              "1795  twitter_1796  ...  [I have been a business customer of MWeb @USER...\n",
              "1796  twitter_1797  ...  [A woman refuses to have her temperature taken...\n",
              "1797  twitter_1798  ...  [The reason big government wants @USER out is ...\n",
              "1798  twitter_1799  ...  [Happy #musicmonday and #thanks for #all your ...\n",
              "1799  twitter_1800  ...  [Not long wrapped on the amazing #January22nd ...\n",
              "\n",
              "[1800 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUbEDzuLsD_h",
        "outputId": "cff8a7e7-a81e-4674-92a7-a25a11a644ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        }
      },
      "source": [
        "# Check maximum character length of 'response'\n",
        "max_response_chars = df.response.str.len().max()\n",
        "print(f\"Maximum character length of 'response': {max_response_chars}\")\n",
        "\n",
        "# Adding 5 extra characters in case special token is needed by the model\n",
        "max_length = max_response_chars + 5 \n",
        "\n",
        "# Review the data\n",
        "df"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Maximum character length of 'response': 310\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>response</th>\n",
              "      <th>context</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>twitter_1</td>\n",
              "      <td>@user @user @user my 3 year old , that just fi...</td>\n",
              "      <td>[Well now that ’ s problematic AF &lt;URL&gt;, @USER...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>twitter_2</td>\n",
              "      <td>@user @user how many verifiable lies has he to...</td>\n",
              "      <td>[Last week the Fake News said that a section o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>twitter_3</td>\n",
              "      <td>@user @user @user maybe docs just a scrub of a...</td>\n",
              "      <td>[@USER Let ’ s Aplaud Brett When he deserves i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>twitter_4</td>\n",
              "      <td>@user @user is just a cover up for the real ha...</td>\n",
              "      <td>[Women generally hate this president . What's ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>twitter_5</td>\n",
              "      <td>@user @user @user the irony being that he even...</td>\n",
              "      <td>[Dear media Remoaners , you excitedly sharing ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1795</th>\n",
              "      <td>twitter_1796</td>\n",
              "      <td>@user @user @user is definitely the best out t...</td>\n",
              "      <td>[I have been a business customer of MWeb @USER...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1796</th>\n",
              "      <td>twitter_1797</td>\n",
              "      <td>@user @user ye let her out run wild and infect...</td>\n",
              "      <td>[A woman refuses to have her temperature taken...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1797</th>\n",
              "      <td>twitter_1798</td>\n",
              "      <td>@user @user @user thanks for that , i would ha...</td>\n",
              "      <td>[The reason big government wants @USER out is ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1798</th>\n",
              "      <td>twitter_1799</td>\n",
              "      <td>@user @user @user yes also #found this on #new...</td>\n",
              "      <td>[Happy #musicmonday and #thanks for #all your ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1799</th>\n",
              "      <td>twitter_1800</td>\n",
              "      <td>@user @user @user you still need to send the l...</td>\n",
              "      <td>[Not long wrapped on the amazing #January22nd ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1800 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                id  ...                                            context\n",
              "0        twitter_1  ...  [Well now that ’ s problematic AF <URL>, @USER...\n",
              "1        twitter_2  ...  [Last week the Fake News said that a section o...\n",
              "2        twitter_3  ...  [@USER Let ’ s Aplaud Brett When he deserves i...\n",
              "3        twitter_4  ...  [Women generally hate this president . What's ...\n",
              "4        twitter_5  ...  [Dear media Remoaners , you excitedly sharing ...\n",
              "...            ...  ...                                                ...\n",
              "1795  twitter_1796  ...  [I have been a business customer of MWeb @USER...\n",
              "1796  twitter_1797  ...  [A woman refuses to have her temperature taken...\n",
              "1797  twitter_1798  ...  [The reason big government wants @USER out is ...\n",
              "1798  twitter_1799  ...  [Happy #musicmonday and #thanks for #all your ...\n",
              "1799  twitter_1800  ...  [Not long wrapped on the amazing #January22nd ...\n",
              "\n",
              "[1800 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgLOsIbvskSO"
      },
      "source": [
        "bert_model = 'bert-large-uncased'\n",
        "batch_size = 5\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(bert_model, do_lower_case=True)\n",
        "\n",
        "encoded_data_evaluation = tokenizer.batch_encode_plus(\n",
        "    df.response.values,\n",
        "    add_special_tokens=True,\n",
        "    return_attention_mask=True,\n",
        "    max_length=max_length,\n",
        "    padding='max_length',\n",
        "    return_tensors='pt'\n",
        ")\n",
        "\n",
        "input_ids_evaluation = encoded_data_evaluation['input_ids']\n",
        "attention_masks_evaluation = encoded_data_evaluation['attention_mask']\n",
        "\n",
        "dataset_evaluation = TensorDataset(input_ids_evaluation, attention_masks_evaluation)\n",
        "\n",
        "dataloader_eval = DataLoader(dataset_evaluation, sampler=SequentialSampler(dataset_evaluation), batch_size=batch_size)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vN2sxGouu2ff",
        "outputId": "f4ca051f-87e0-4857-9afc-f88d54e7fb6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 813
        }
      },
      "source": [
        "# If GPU is available.\n",
        "if torch.cuda.is_available():    \n",
        "    # PyTorch to use the GPU    \n",
        "    device = torch.device(\"cuda\")\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "# If GPU is not available. Use the CPU.\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "# To set the model into a training mode\n",
        "label_dict = {'SARCASM': 0, 'NOT_SARCASM': 1}\n",
        "bert_model = 'bert-large-uncased'\n",
        "model = BertForSequenceClassification.from_pretrained(bert_model,\n",
        "                                                      num_labels=len(label_dict),\n",
        "                                                      output_attentions=False,\n",
        "                                                      output_hidden_states=False)\n",
        "model.to(device)\n",
        "model.load_state_dict(torch.load(model_file, map_location=torch.device(device)))\n",
        "\n",
        "model.eval()\n",
        "loss_val_total = 0\n",
        "predictions = []\n",
        "\n",
        "for batch in dataloader_eval:\n",
        "  batch = tuple(b.to(device) for b in batch)\n",
        "  inputs = {'input_ids': batch[0], 'attention_mask': batch[1]}\n",
        "\n",
        "  with torch.no_grad():\n",
        "    # evaluate the validation dataset\n",
        "    output = model(**inputs)\n",
        "    logits = output[0]\n",
        "    # print(output)\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    predictions.append(logits)\n",
        "\n",
        "predictions = np.concatenate(predictions, axis=0)\n",
        "preds_flat = np.argmax(predictions, axis=1).flatten()\n",
        "\n",
        "\n",
        "print('######################')\n",
        "print('# Evaluation is done #')\n",
        "print('######################')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No GPU available, using the CPU instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-f250e1ba869f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m                                                       output_hidden_states=False)\n\u001b[1;32m     19\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1050\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m-> 1052\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m   1053\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for BertForSequenceClassification:\n\tMissing key(s) in state_dict: \"bert.embeddings.position_ids\", \"bert.embeddings.word_embeddings.weight\", \"bert.embeddings.position_embeddings.weight\", \"bert.embeddings.token_type_embeddings.weight\", \"bert.embeddings.LayerNorm.weight\", \"bert.embeddings.LayerNorm.bias\", \"bert.encoder.layer.0.attention.self.query.weight\", \"bert.encoder.layer.0.attention.self.query.bias\", \"bert.encoder.layer.0.attention.self.key.weight\", \"bert.encoder.layer.0.attention.self.key.bias\", \"bert.encoder.layer.0.attention.self.value.weight\", \"bert.encoder.layer.0.attention.self.value.bias\", \"bert.encoder.layer.0.attention.output.dense.weight\", \"bert.encoder.layer.0.attention.output.dense.bias\", \"bert.encoder.layer.0.attention.output.LayerNorm.weight\", \"bert.encoder.layer.0.attention.output.LayerNorm.bias\", \"bert.encoder.layer.0.intermediate.dense.weight\", \"bert.encoder.layer.0.intermediate.dense.bias\", \"bert.encoder.layer.0.output.dense.weight\", \"bert.encoder.layer.0.output.dense.bias\", \"bert.encoder.layer.0.output.LayerNorm.weight\", \"bert.encoder.layer.0.output.LayerNorm.bias\", \"bert.encoder.layer.1.attention.self.query.weight\", \"bert.encoder.layer.1.attention.self.query.bias\", \"bert.encoder.layer.1.attention.self.key.weight\", \"bert.encoder.layer.1.attention.self.key.bias\", \"bert.encoder.layer.1.attention.self.value.weight\", \"bert.encoder.layer.1.attention.self.value.bias\", \"bert.encoder.layer.1.attention.output.dense.weight\", \"bert.encoder.layer.1.attention.output.dense.bias\", \"bert.encoder.layer....\n\tUnexpected key(s) in state_dict: \"roberta.embeddings.position_ids\", \"roberta.embeddings.word_embeddings.weight\", \"roberta.embeddings.position_embeddings.weight\", \"roberta.embeddings.token_type_embeddings.weight\", \"roberta.embeddings.LayerNorm.weight\", \"roberta.embeddings.LayerNorm.bias\", \"roberta.encoder.layer.0.attention.self.query.weight\", \"roberta.encoder.layer.0.attention.self.query.bias\", \"roberta.encoder.layer.0.attention.self.key.weight\", \"roberta.encoder.layer.0.attention.self.key.bias\", \"roberta.encoder.layer.0.attention.self.value.weight\", \"roberta.encoder.layer.0.attention.self.value.bias\", \"roberta.encoder.layer.0.attention.output.dense.weight\", \"roberta.encoder.layer.0.attention.output.dense.bias\", \"roberta.encoder.layer.0.attention.output.LayerNorm.weight\", \"roberta.encoder.layer.0.attention.output.LayerNorm.bias\", \"roberta.encoder.layer.0.intermediate.dense.weight\", \"roberta.encoder.layer.0.intermediate.dense.bias\", \"roberta.encoder.layer.0.output.dense.weight\", \"roberta.encoder.layer.0.output.dense.bias\", \"roberta.encoder.layer.0.output.LayerNorm.weight\", \"roberta.encoder.layer.0.output.LayerNorm.bias\", \"roberta.encoder.layer.1.attention.self.query.weight\", \"roberta.encoder.layer.1.attention.self.query.bias\", \"roberta.encoder.layer.1.attention.self.key.weight\", \"roberta.encoder.layer.1.attention.self.key.bias\", \"roberta.encoder.layer.1.attention.self.value.weight\", \"roberta.encoder.layer.1.attention.self.value.bias\", \"roberta.encoder.layer.1.attention.outp..."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Db9MRxaE4Lnu"
      },
      "source": [
        "# answer.txt\n",
        "i = 1\n",
        "for pred in enumerate(preds_flat):\n",
        "  if pred[1] == 0:\n",
        "    text = 'SARCASM'\n",
        "  else:\n",
        "    text = 'NOT_SARCASM'\n",
        "  print('twitter_{0},{1}'.format(i, text))\n",
        "  i = i + 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ovc-DK-j58aV"
      },
      "source": [
        "# Summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLZqg5Nn0-45"
      },
      "source": [
        "- f1 = 0.757905138339921\n",
        "- recall = 0.8522222222222222\n",
        "- precision = 0.6823843416370107\n",
        "\n",
        "Baseline score (f1, recall and precision) is 0.723"
      ]
    }
  ]
}