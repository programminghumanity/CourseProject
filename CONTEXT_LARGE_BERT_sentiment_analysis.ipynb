{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CONTEXT_LARGE_BERT_sentiment_analysis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNECj4BbGhQuSc4GYGFUqvz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d4acc8b93c60434bb6b2c9352bd71bd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_68ea9951e47e42d193bf4396d902d3e2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_154d22d224f4484b8c9e5f486bcf79b2",
              "IPY_MODEL_6a47a7f16dff4ae9b3cfe8b61fea4a73"
            ]
          }
        },
        "68ea9951e47e42d193bf4396d902d3e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "154d22d224f4484b8c9e5f486bcf79b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7b39dbfebbf04636abb5928d980389e8",
            "_dom_classes": [],
            "description": "  0%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 4,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_df199a36f0634cb6b0463c60ba12e3ad"
          }
        },
        "6a47a7f16dff4ae9b3cfe8b61fea4a73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_bbf2e8d730b44cd5bf453efcb3a20347",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/4 [00:00&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9a0464bf5e154db09ec1b15620dc4e91"
          }
        },
        "7b39dbfebbf04636abb5928d980389e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "df199a36f0634cb6b0463c60ba12e3ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bbf2e8d730b44cd5bf453efcb3a20347": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9a0464bf5e154db09ec1b15620dc4e91": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "beb80871f8b04f9e92e73eae69fff025": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_cdbfdb70f83e40a68ea42fcb3daaa820",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6de382bb551946b780c12550cfdc0f94",
              "IPY_MODEL_58c3aaa03e3347d9a15161d42d5b5f39"
            ]
          }
        },
        "cdbfdb70f83e40a68ea42fcb3daaa820": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6de382bb551946b780c12550cfdc0f94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_09e06cfc06274787a378fd7261e944ae",
            "_dom_classes": [],
            "description": "Epoch 1:   0%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 5000,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 5,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c9946bb3060c4888a91186750a950817"
          }
        },
        "58c3aaa03e3347d9a15161d42d5b5f39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7046e4f4287a450183ee5a5920a5945d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5/5000 [02:06&lt;34:35:16, 24.93s/it, training_loss=0.537]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6dc7712c93f54a938888869a5659cbf8"
          }
        },
        "09e06cfc06274787a378fd7261e944ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c9946bb3060c4888a91186750a950817": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7046e4f4287a450183ee5a5920a5945d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6dc7712c93f54a938888869a5659cbf8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zen030/CourseProject/blob/main/CONTEXT_LARGE_BERT_sentiment_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-69l_vOokYo"
      },
      "source": [
        "# **This notebook is implemented and tested in Google Colab PRO environment**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ok_kqpU75gc7"
      },
      "source": [
        "# 1. Colab Configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYgfhvWdlo61",
        "outputId": "91910fef-dc46-4144-ba64-d9a89e8a920c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install transformers\n",
        "!pip install PyDrive"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (3.4.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers) (3.12.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: tokenizers==0.9.2 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.9.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.94)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (50.3.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: PyDrive in /usr/local/lib/python3.6/dist-packages (1.3.1)\n",
            "Requirement already satisfied: google-api-python-client>=1.2 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (1.7.12)\n",
            "Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (4.1.3)\n",
            "Requirement already satisfied: PyYAML>=3.0 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (3.13)\n",
            "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (1.17.2)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (3.0.1)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (0.17.4)\n",
            "Requirement already satisfied: six<2dev,>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (1.15.0)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (0.0.4)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (4.6)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.2.8)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client>=1.2->PyDrive) (50.3.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client>=1.2->PyDrive) (4.1.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCCQxDTOnwis",
        "outputId": "eab69dd1-9ac4-4a16-8a36-d6711e6a1276",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import torch\n",
        "\n",
        "# If GPU is available.\n",
        "if torch.cuda.is_available():    \n",
        "    # PyTorch to use the GPU    \n",
        "    device = torch.device(\"cuda\")\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "# If GPU is not available. Use the CPU.\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No GPU available, using the CPU instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wETMfBQ0lLSQ"
      },
      "source": [
        "# To manage dataset\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# train.json file location: https://drive.google.com/file/d/1d5lwaHPOUBAz7c-cNXXQeFn75ZV2HkUh/view?usp=sharing\n",
        "# test.jsonl file location: https://drive.google.com/file/d/1vA3uyqy1TZmahgZ0PeNRFx67LuYeAkoW/view?usp=sharing\n",
        "\n",
        "# The training dataset\n",
        "# Google Drive file name\n",
        "training_file = 'train.jsonl'\n",
        "# Google Drive unique file ID\n",
        "training_file_id = '1d5lwaHPOUBAz7c-cNXXQeFn75ZV2HkUh'\n",
        "\n",
        "\n",
        "# The evaluation/testing dataset\n",
        "# Google Drive file name\n",
        "evaluation_file = 'test.jsonl'\n",
        "# Google Drive unique file ID\n",
        "test_jsonl_file_id = \"1vA3uyqy1TZmahgZ0PeNRFx67LuYeAkoW\""
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8OtoBZZGnzeP"
      },
      "source": [
        "# The files are shared to public.\n",
        "# Login using Google Account to proceed.\n",
        "# Copy-past the code.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "downloaded = drive.CreateFile({'id':training_file_id})\n",
        "downloaded.GetContentFile(training_file)\n",
        "\n",
        "downloaded = drive.CreateFile({'id':test_jsonl_file_id})\n",
        "downloaded.GetContentFile(evaluation_file)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TtezXbQs5rur"
      },
      "source": [
        "# 2. Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTheprk_lrur"
      },
      "source": [
        "# import modules\n",
        "\n",
        "import pandas as pd\n",
        "import json\n",
        "from transformers import BertTokenizer\n",
        "from torch.utils.data import TensorDataset\n",
        "from transformers import BertForSequenceClassification\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "import numpy as np\n",
        "from sklearn.metrics import f1_score"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHQ3l6ohAvpU",
        "outputId": "5e49ae35-f57c-4f57-f6d2-4e7a4829f811",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Read jsonl file into list (of json)\n",
        "with open(training_file) as f:\n",
        "    # creating array of json\n",
        "    lines = f.read().splitlines()\n",
        "print(f'Number of lines in file: {len(lines)}')\n",
        "\n",
        "# Normalize json into dataframe columns\n",
        "df = pd.json_normalize(pd.DataFrame(lines)[0].apply(json.loads))\n",
        "print(f'Number of records in Pandas DataFrame: {len(df)}')\n",
        "\n",
        "# Lowercase response text.\n",
        "# BERT Model can lowercase the text in the setting.\n",
        "# I choose to lowercase the text here to have a uniform text format.\n",
        "# In case I need to modify the text for data cleaning before training the model.\n",
        "# df.response = df.response.str.lower()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of lines in file: 5000\n",
            "Number of records in Pandas DataFrame: 5000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VnPiAbQlAkI2",
        "outputId": "47dd0c2e-0ab2-47d7-d8df-1e1ff8dd1221",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        }
      },
      "source": [
        "# Add 'label_value' integer column.\n",
        "#    0 for SARCASM\n",
        "#    1 for NOT_SARCASM\n",
        "label_dict = {'SARCASM': 0, 'NOT_SARCASM': 1}\n",
        "df['label_value'] = df.label.replace(label_dict)\n",
        "\n",
        "# Print maximum character length of 'response'\n",
        "max_response_chars = df.response.str.len().max()\n",
        "print(f\"Maximum character length of 'response': {max_response_chars}\")\n",
        "\n",
        "# Adding 5 extra characters in case special token is needed by model\n",
        "max_length = 512\n",
        "\n",
        "# Preview response data\n",
        "df"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Maximum character length of 'response': 315\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>response</th>\n",
              "      <th>context</th>\n",
              "      <th>label_value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>SARCASM</td>\n",
              "      <td>@USER @USER @USER I don't get this .. obviousl...</td>\n",
              "      <td>[A minor child deserves privacy and should be ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SARCASM</td>\n",
              "      <td>@USER @USER trying to protest about . Talking ...</td>\n",
              "      <td>[@USER @USER Why is he a loser ? He's just a P...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>SARCASM</td>\n",
              "      <td>@USER @USER @USER He makes an insane about of ...</td>\n",
              "      <td>[Donald J . Trump is guilty as charged . The e...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>SARCASM</td>\n",
              "      <td>@USER @USER Meanwhile Trump won't even release...</td>\n",
              "      <td>[Jamie Raskin tanked Doug Collins . Collins lo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>SARCASM</td>\n",
              "      <td>@USER @USER Pretty Sure the Anti-Lincoln Crowd...</td>\n",
              "      <td>[Man ... y ’ all gone “ both sides ” the apoca...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4995</th>\n",
              "      <td>NOT_SARCASM</td>\n",
              "      <td>@USER You don't . I have purchased a lot on Am...</td>\n",
              "      <td>[@USER Apologies for the inconvenience you fac...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4996</th>\n",
              "      <td>NOT_SARCASM</td>\n",
              "      <td>@USER #Emotions you say 🤔 never knew that I th...</td>\n",
              "      <td>[@USER 🤔 idk tho , I think I ’ m #hungry . But...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4997</th>\n",
              "      <td>NOT_SARCASM</td>\n",
              "      <td>@USER @USER @USER You are so right ... \" Yes !...</td>\n",
              "      <td>[@USER @USER @USER Peace to you , and two coun...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4998</th>\n",
              "      <td>NOT_SARCASM</td>\n",
              "      <td>@USER @USER @USER Another lazy delusional vote...</td>\n",
              "      <td>[Bernie Sanders told Elizabeth Warren in priva...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4999</th>\n",
              "      <td>NOT_SARCASM</td>\n",
              "      <td>@USER @USER I hope you know no news outlet fro...</td>\n",
              "      <td>[PDP PROTEST BRAINSTORMING SESSION Deji : We n...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5000 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            label  ... label_value\n",
              "0         SARCASM  ...           0\n",
              "1         SARCASM  ...           0\n",
              "2         SARCASM  ...           0\n",
              "3         SARCASM  ...           0\n",
              "4         SARCASM  ...           0\n",
              "...           ...  ...         ...\n",
              "4995  NOT_SARCASM  ...           1\n",
              "4996  NOT_SARCASM  ...           1\n",
              "4997  NOT_SARCASM  ...           1\n",
              "4998  NOT_SARCASM  ...           1\n",
              "4999  NOT_SARCASM  ...           1\n",
              "\n",
              "[5000 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMbTCZA-hgrf",
        "outputId": "a3d46671-dbab-4037-d429-96da34be44fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "# Combine response and context\n",
        "df['response'] = df['response'] + '[SEP]'\n",
        "for index in df.index: \n",
        "  contexts = ''\n",
        "  for context in reversed(df['context'][index]):\n",
        "    contexts = contexts + ' ' + context\n",
        "  df['response'][index] = df['response'][index] + contexts\n",
        "\n",
        "# Check first record\n",
        "df.response[0]"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"@USER @USER @USER I don't get this .. obviously you do care or you would've moved right along .. instead you decided to care and troll her ..[SEP] @USER If your child isn't named Barron ... #BeBest Melania couldn't care less . Fact . 💯 A minor child deserves privacy and should be kept out of politics . Pamela Karlan , you should be ashamed of your very angry and obviously biased public pandering , and using a child to do it .\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcyTGtCFH0Jt",
        "outputId": "2eba8f26-6b1f-49f6-8e63-4e9f76e0c750",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Preparing BERT Token for the training dataset.\n",
        "# BERT Tokenizing using HuggingFace Transformers library\n",
        "# (https://github.com/huggingface/transformers)\n",
        "bert_model = 'bert-large-uncased'\n",
        "batch_size = 1\n",
        "epochs = 4\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(bert_model, do_lower_case=True)\n",
        "\n",
        "encoded_data_training = tokenizer.batch_encode_plus(\n",
        "    df.response.values,\n",
        "    add_special_tokens=True,\n",
        "    return_attention_mask=True,\n",
        "    max_length=max_length,\n",
        "    padding='max_length',\n",
        "    return_tensors='pt',\n",
        "    truncation=True\n",
        ")\n",
        "\n",
        "input_ids_training = encoded_data_training['input_ids']\n",
        "attention_masks_training = encoded_data_training['attention_mask']\n",
        "labels_training = torch.tensor(df.label_value.values)\n",
        "\n",
        "\n",
        "dataset_training = TensorDataset(input_ids_training, attention_masks_training, labels_training)\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(bert_model,\n",
        "                                                      num_labels=len(label_dict),\n",
        "                                                      output_attentions=False,\n",
        "                                                      output_hidden_states=False)\n",
        "model.to(device)\n",
        "\n",
        "\n",
        "data_loader_train = DataLoader(dataset_training, sampler=RandomSampler(dataset_training), batch_size=batch_size)\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5, eps=1e-8)\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(dataset_training)*epochs)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NenFOamfpRv_",
        "outputId": "4c6b5354-cf15-4310-e765-e3b071dafc06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "d4acc8b93c60434bb6b2c9352bd71bd4",
            "68ea9951e47e42d193bf4396d902d3e2",
            "154d22d224f4484b8c9e5f486bcf79b2",
            "6a47a7f16dff4ae9b3cfe8b61fea4a73",
            "7b39dbfebbf04636abb5928d980389e8",
            "df199a36f0634cb6b0463c60ba12e3ad",
            "bbf2e8d730b44cd5bf453efcb3a20347",
            "9a0464bf5e154db09ec1b15620dc4e91",
            "beb80871f8b04f9e92e73eae69fff025",
            "cdbfdb70f83e40a68ea42fcb3daaa820",
            "6de382bb551946b780c12550cfdc0f94",
            "58c3aaa03e3347d9a15161d42d5b5f39",
            "09e06cfc06274787a378fd7261e944ae",
            "c9946bb3060c4888a91186750a950817",
            "7046e4f4287a450183ee5a5920a5945d",
            "6dc7712c93f54a938888869a5659cbf8"
          ]
        }
      },
      "source": [
        "#######################################################\n",
        "# Here we will train the model using training dataset #\n",
        "#######################################################\n",
        "\n",
        "from tqdm.notebook import tqdm # https://github.com/tqdm/tqdm\n",
        "import random\n",
        "\n",
        "# The random seed used to initialise the weights.\n",
        "# and select the order of the training data.\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "\n",
        "# All of the above assume the code was run on a CPU.\n",
        "# It is possible that when using the GPU to train the models, \n",
        "# the backend may be configured to use a sophisticated stack of GPU libraries, \n",
        "# and that some of these may introduce their own source of randomness.\n",
        "# For example, there is some evidence that if we are using Nvidia cuDNN, \n",
        "# that this may introduce additional sources of randomness and prevent \n",
        "# the exact reproducibility of results.\n",
        "seed_val = 17\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# loop over the full dataset for a number of epochs times.\n",
        "for epoch in tqdm(range(epochs)):\n",
        "    \n",
        "    # To set the model into a training mode.\n",
        "    model.train()\n",
        "    \n",
        "    # Measure the total training loss for each epoch.\n",
        "    loss_train_total = 0\n",
        "    # Progressbar to show the progress of the current epoch.\n",
        "    progress_bar = tqdm(data_loader_train, desc='Epoch {:1d}'.format(epoch+1), leave=False, disable=False)\n",
        "    \n",
        "    # Process each batch in the current epoch.\n",
        "    for batch in progress_bar:\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a backward pass. \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()\n",
        "        \n",
        "        # Unpack current training batch.\n",
        "        # batch contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        batch = tuple(b.to(device) for b in batch)\n",
        "        \n",
        "        inputs = {'input_ids':      batch[0],\n",
        "                  'attention_mask': batch[1],\n",
        "                  'labels':         batch[2],\n",
        "                 }       \n",
        "\n",
        "        # This is the actual learning.\n",
        "        outputs = model(**inputs)\n",
        "        \n",
        "        # Current training loss.\n",
        "        loss = outputs[0]\n",
        "        # Current total training loss.\n",
        "        loss_train_total = loss_train_total + loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "        \n",
        "        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})\n",
        "         \n",
        "    # Save the trained BERT model for the current epoch iteration    \n",
        "    torch.save(model.state_dict(), f'CONTEXT_BASE_BERT_epoch_{epoch+1}.model')\n",
        "\n",
        "    # Report the summary of epoch iteration\n",
        "    tqdm.write(f'\\nEpoch {epoch+1} is completed')\n",
        "\n",
        "tqdm.write(f'\\n#########################')\n",
        "tqdm.write(f'\\n# Training is completed #')\n",
        "tqdm.write(f'\\n#########################')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d4acc8b93c60434bb6b2c9352bd71bd4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "beb80871f8b04f9e92e73eae69fff025",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Epoch 1', max=5000.0, style=ProgressStyle(description_wid…"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDPdGFOi54MM"
      },
      "source": [
        "# 3. Evaluation\n",
        "\n",
        "To evaluate the trained model.\n",
        "The evaluation of trained model used to post 'answer.txt' is available here:\n",
        "https://github.com/zen030/CourseProject/blob/main/Evaluation_NAIVE_BERT_sentiment_analysis.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hO6nF2RTZ_ld"
      },
      "source": [
        "# Read testing/evaluation jsonl file into list (of json)\n",
        "evaluation_data_file = evaluation_file\n",
        "with open(evaluation_data_file) as f:\n",
        "    # creating array of json\n",
        "    lines = f.read().splitlines()\n",
        "print(f'Number of lines in file: {len(lines)}')\n",
        "\n",
        "# Normalize json into dataframe columns\n",
        "df = pd.json_normalize(pd.DataFrame(lines)[0].apply(json.loads))\n",
        "print(f'Number of records in Pandas DataFrame: {len(df)}')\n",
        "\n",
        "# Lowercase response text\n",
        "# BERT Model can lowercase the text in the setting\n",
        "# I choose to lowercase the text here to have a uniform text format\n",
        "# In case I need to modfiy the text for a reason\n",
        "df.response = df.response.str.lower()\n",
        "\n",
        "# Print maximum character length of 'response'\n",
        "max_response_chars = df.response.str.len().max()\n",
        "print(f\"Maximum character length of 'response': {max_response_chars}\")\n",
        "\n",
        "# Adding 5 extra characters in case special token is needed by model\n",
        "max_length = 512\n",
        "\n",
        "# Preview the response data\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RnK8j_jj0nn"
      },
      "source": [
        "# Combine response and context\n",
        "df['response'] = df['response'] + '[SEP]'\n",
        "for index in df.index: \n",
        "  contexts = ''\n",
        "  for context in reversed(df['context'][index]):\n",
        "    contexts = contexts + ' ' + context\n",
        "  df['response'][index] = df['response'][index] + contexts\n",
        "\n",
        "# Check first record\n",
        "df.response[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgLOsIbvskSO"
      },
      "source": [
        "bert_model = 'bert-large-uncased'\n",
        "batch_size = 5\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(bert_model, do_lower_case=True)\n",
        "\n",
        "print(tokenizer)\n",
        "\n",
        "encoded_data_evaluation = tokenizer.batch_encode_plus(\n",
        "    df.response.values,\n",
        "    add_special_tokens=True,\n",
        "    return_attention_mask=True,\n",
        "    max_length=max_length,\n",
        "    padding='max_length',\n",
        "    return_tensors='pt',\n",
        "    truncation=True\n",
        ")\n",
        "\n",
        "input_ids_evaluation = encoded_data_evaluation['input_ids']\n",
        "attention_masks_evaluation = encoded_data_evaluation['attention_mask']\n",
        "\n",
        "dataset_evaluation = TensorDataset(input_ids_evaluation, attention_masks_evaluation)\n",
        "\n",
        "dataloader_eval = DataLoader(dataset_evaluation, sampler=SequentialSampler(dataset_evaluation), batch_size=batch_size)\n",
        "\n",
        "print(input_ids_evaluation[0])\n",
        "print(input_ids_evaluation[1])\n",
        "\n",
        "\n",
        "dataset_evaluation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vN2sxGouu2ff"
      },
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "# If GPU is available.\n",
        "if torch.cuda.is_available():    \n",
        "    # PyTorch to use the GPU    \n",
        "    device = torch.device(\"cuda\")\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "# If GPU is not available. Use the CPU.\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "# To set the model into a training mode\n",
        "label_dict = {'SARCASM': 0, 'NOT_SARCASM': 1}\n",
        "bert_model = 'bert-large-uncased'\n",
        "model = BertForSequenceClassification.from_pretrained(bert_model,\n",
        "                                                      num_labels=len(label_dict),\n",
        "                                                      output_attentions=False,\n",
        "                                                      output_hidden_states=False)\n",
        "model.to(device)\n",
        "model.load_state_dict(torch.load('CONTEXT_BASE_BERT_epoch_4.model', map_location=torch.device(device)))\n",
        "\n",
        "model.eval()\n",
        "loss_val_total = 0\n",
        "predictions = []\n",
        "\n",
        "for batch in dataloader_eval:\n",
        "  batch = tuple(b.to(device) for b in batch)\n",
        "  inputs = {'input_ids': batch[0], 'attention_mask': batch[1]}\n",
        "\n",
        "  with torch.no_grad():\n",
        "    # evaluate the validation dataset\n",
        "    output = model(**inputs)\n",
        "    logits = output[0]\n",
        "    print(batch[0])\n",
        "    print(batch[1])\n",
        "    print(logits)\n",
        "    # print(output)\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    predictions.append(logits)\n",
        "\n",
        "predictions = np.concatenate(predictions, axis=0)\n",
        "preds_flat = np.argmax(predictions, axis=1).flatten()\n",
        "\n",
        "print(preds_flat)\n",
        "\n",
        "print('Evaluation is done')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fnv-UWESg_D2"
      },
      "source": [
        "tokenizer.convert_ids_to_tokens([12105])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Db9MRxaE4Lnu"
      },
      "source": [
        "# Generate 'answer.txt'\n",
        "i = 1\n",
        "for pred in enumerate(preds_flat):\n",
        "  if pred[1] == 0:\n",
        "    text = 'SARCASM'\n",
        "  else:\n",
        "    text = 'NOT_SARCASM'\n",
        "  print('twitter_{0},{1}'.format(i, text))\n",
        "  i = i + 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ovc-DK-j58aV"
      },
      "source": [
        "# 4. Summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLZqg5Nn0-45"
      },
      "source": [
        "Final model and evaluation result are available here: \n",
        "https://github.com/zen030/CourseProject/blob/main/Evaluation_NAIVE_BERT_sentiment_analysis.ipynb"
      ]
    }
  ]
}